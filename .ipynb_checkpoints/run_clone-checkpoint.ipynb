{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "import load_policy\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense #, Dropout, Activation, Flatten, Reshape\n",
    "#from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_task_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        task_data = pickle.loads(f.read())\n",
    "    return task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_rollouts = 20\n",
    "expert_name = \"Hopper-v1\"\n",
    "#expert_name = \"Ant-v1\"\n",
    "#expert_name = \"HalfCheetah-v1\"\n",
    "#expert_name = \"Humanoid-v1\"\n",
    "#expert_name = \"Reacher-v1\"\n",
    "#expert_name = \"Walker2d-v1\"\n",
    "data_file = \"data/Hopper-v1_20_data.pkl\"\n",
    "#data_file = \"Humanoid-v1_10_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_clone(expert_name, expert_data_file, render = False, num_rollouts = 20):\n",
    "    #expert_name: the gym expert policy name\n",
    "    #render: True to render\n",
    "    #num_rollouts\n",
    "    \n",
    "    print('loading and building expert policy')\n",
    "    expert_policy_file = \"./experts/\" + expert_name + \".pkl\"\n",
    "    policy_fn = load_policy.load_policy(expert_policy_file)\n",
    "    print('loaded and built')\n",
    "\n",
    "    task_data = load_task_data(expert_data_file) #\"data/\" + data_file + \".pkl\")\n",
    "    obs_data = np.array(task_data[\"observations\"])\n",
    "    act_data = np.array(task_data[\"actions\"])\n",
    "\n",
    "    act_data = act_data.reshape(act_data.shape[0], act_data.shape[2])\n",
    "\n",
    "    #create a Feedforward network useing Keras\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, activation = \"relu\", input_shape = (obs_data.shape[1],)))\n",
    "    model.add(Dense(96, activation = \"relu\"))\n",
    "    model.add(Dense(96, activation = \"relu\"))\n",
    "    model.add(Dense(act_data.shape[1], activation = \"linear\"))\n",
    "\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(obs_data, act_data, batch_size = 64, epochs = 30, verbose = 1)\n",
    "\n",
    "    model.save('models/' + expert_name + '_cloned_model.h5')\n",
    "\n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "\n",
    "        env = gym.make(expert_name)\n",
    "        max_steps = env.spec.timestep_limit\n",
    "\n",
    "        returns = []\n",
    "        cloned_observations = []\n",
    "        cloned_actions = []\n",
    "        for i in range(num_rollouts):\n",
    "            print('iter', i)\n",
    "            obs = env.reset()\n",
    "\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "\n",
    "            cloned_model = load_model('models/' + expert_name + '_cloned_model.h5')\n",
    "            while not done:\n",
    "                action = cloned_model.predict(obs[None, :], batch_size = 64, verbose = 0)\n",
    "                cloned_observations.append(obs)\n",
    "                cloned_actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "        \n",
    "        return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "loaded and built\n",
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.1698 - acc: 0.8569\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0211 - acc: 0.9353\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0145 - acc: 0.9451\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0106 - acc: 0.9552\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0081 - acc: 0.9614\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0071 - acc: 0.9630\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 2s 76us/step - loss: 0.0059 - acc: 0.9662\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0052 - acc: 0.9683\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.0045 - acc: 0.9702\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0043 - acc: 0.9711\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.0037 - acc: 0.9719\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0030 - acc: 0.9758\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.0038 - acc: 0.9728\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 1s 71us/step - loss: 0.0028 - acc: 0.9769\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0024 - acc: 0.9786\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.0027 - acc: 0.9772\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 0.0030 - acc: 0.978 - 1s 60us/step - loss: 0.0030 - acc: 0.9775\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0022 - acc: 0.9805\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.0019 - acc: 0.9805\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.0021 - acc: 0.9798\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.0020 - acc: 0.9814\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.0021 - acc: 0.9813\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0021 - acc: 0.9808\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.0016 - acc: 0.9809\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 1s 70us/step - loss: 0.0019 - acc: 0.9819\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.0018 - acc: 0.9828\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.0014 - acc: 0.9842\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.0018 - acc: 0.9829\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.0019 - acc: 0.9832\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0014 - acc: 0.9832\n",
      "WARNING:tensorflow:From /home/tiger/Downloads/projects/CS294/hw1/tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-15 18:56:26,896] From /home/tiger/Downloads/projects/CS294/hw1/tf_util.py:91: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tiger/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-15 18:56:26,930] From /home/tiger/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n",
      "[2018-04-15 18:56:26,990] Making new env: Hopper-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 1\n",
      "100/1000\n",
      "200/1000\n",
      "iter 2\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 3\n",
      "100/1000\n",
      "200/1000\n",
      "iter 4\n",
      "100/1000\n",
      "200/1000\n",
      "iter 5\n",
      "100/1000\n",
      "200/1000\n",
      "iter 6\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 7\n",
      "100/1000\n",
      "200/1000\n",
      "iter 8\n",
      "100/1000\n",
      "200/1000\n",
      "iter 9\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 10\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "400/1000\n",
      "iter 11\n",
      "100/1000\n",
      "200/1000\n",
      "iter 12\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 13\n",
      "100/1000\n",
      "200/1000\n",
      "iter 14\n",
      "100/1000\n",
      "200/1000\n",
      "iter 15\n",
      "100/1000\n",
      "200/1000\n",
      "iter 16\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 17\n",
      "100/1000\n",
      "200/1000\n",
      "iter 18\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "iter 19\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "returns [1142.2000455096504, 1025.7074998333846, 1091.5494892982056, 1012.9702134223995, 1011.7602469172207, 987.84741118566069, 1087.8001557553287, 984.42417339449651, 1045.8000951330516, 1042.504440457865, 1425.8758478500986, 1039.3521516661021, 1143.0014750754353, 1015.5517126081781, 959.70416632304511, 978.40802709342745, 1164.01770002955, 986.41262674329346, 1138.5857582813976, 1162.1179822970003]\n",
      "mean return 1072.27956094\n",
      "std of return 103.769228102\n"
     ]
    }
   ],
   "source": [
    "returns = run_clone(expert_name, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns [1142.2000455096504, 1025.7074998333846, 1091.5494892982056, 1012.9702134223995, 1011.7602469172207, 987.84741118566069, 1087.8001557553287, 984.42417339449651, 1045.8000951330516, 1042.504440457865, 1425.8758478500986, 1039.3521516661021, 1143.0014750754353, 1015.5517126081781, 959.70416632304511, 978.40802709342745, 1164.01770002955, 986.41262674329346, 1138.5857582813976, 1162.1179822970003]\n",
      "mean return 1072.27956094\n",
      "std of return 103.769228102\n"
     ]
    }
   ],
   "source": [
    "print('returns', returns)\n",
    "print('mean return', np.mean(returns))\n",
    "print('std of return', np.std(returns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
